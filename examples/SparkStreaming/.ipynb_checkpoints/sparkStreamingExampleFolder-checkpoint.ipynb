{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vital-topic",
   "metadata": {},
   "source": [
    "# ***Spark Streaming Word Count problem - Folder example***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interstate-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "#import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "informal-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder = './testSparkStreaming'\n",
    "outputPathPrefix = './resSparkStreaming/resSparkStreamingExamples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "lined-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark Straming Context object\n",
    "ssc = StreamingContext(sc, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "increasing-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a (Receivver) DStream that will read new data from an input folder\n",
    "lines = ssc.textFileStream(inputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dutch-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the \"standard\" transformations to perform the word count task\n",
    "# However, the \"returned\" RDDs are DStream RDDs\n",
    "words = lines.flatMap(lambda line: line.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "manual-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsOnes = words.map(lambda word: (word, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rental-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsCounts = wordsOnes.reduceByKey(lambda v1, v2: v1+v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "italic-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsCounts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "supreme-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsCounts.saveAsTextFiles(outputPathPrefix, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "authorized-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:42:50\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:42:55\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:43:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:43:05\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:43:10\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:43:15\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:43:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:43:25\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start the computation\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "saving-representation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-06-12 08:44:55\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this application for 90 seconds\n",
    "ssc.awaitTerminationOrTimeout(90)\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "medical-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-madison",
   "metadata": {},
   "source": [
    "**Note:** if the file already exists, the system will not considerate it, also if you append anything at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-clinton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
