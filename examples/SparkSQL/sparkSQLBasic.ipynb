{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "painted-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of basic SparkSQL commands\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# Create a Spark session obj\n",
    "sp = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-testimony",
   "metadata": {},
   "source": [
    "# CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charming-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DF from persons.csv\n",
    "df = spark.read.load('./databases/persons.csv', format='csv', header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empirical-cornell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   Name| Age|\n",
      "+-------+----+\n",
      "| Justin|  19|\n",
      "|   Andy|  30|\n",
      "|Michael|null|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hawaiian-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to rename columns\n",
    "df2 = df.withColumnRenamed(\"nome\", \"eta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elegant-avenue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n",
      "+-------+----+\n",
      "|   Name| Age|\n",
      "+-------+----+\n",
      "| Justin|  19|\n",
      "|   Andy|  30|\n",
      "|Michael|null|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-adjustment",
   "metadata": {},
   "source": [
    "# JSON file\n",
    "**NOTE:** in JSON files, spark authomatically infers the datatypes of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "appropriate-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 30|   John|\n",
      "| 13|Michael|\n",
      "| 19|  Perdo|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example with an input json file - inline format\n",
    "df = spark.read.load( \"./databases/persons.json\", format=\"json\" )\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chicken-ottawa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 30|Michael|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One JSON file for each input file\n",
    "df = spark.read.load(\"./databases/p1.json\", format=\"json\", multiLine=True)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "revolutionary-cedar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- eta: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+---+-------+\n",
      "|eta|   name|\n",
      "+---+-------+\n",
      "| 30|   John|\n",
      "| 13|Michael|\n",
      "| 19|  Perdo|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How to rename columns\n",
    "df2 = df.withColumnRenamed(\"age\", \"eta\") # (\"nameOfOldColumn\", \"nameOfNewColumn\")\n",
    "\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-bidder",
   "metadata": {},
   "source": [
    "### **Example - change columns name and build an RDD**\n",
    "Create a DF from a persons_noheader.csv and rename its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lesser-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n",
      "+----------+---+\n",
      "|      name|age|\n",
      "+----------+---+\n",
      "| Arcangelo| 23|\n",
      "|  Leonardo| 24|\n",
      "|Margherita| 10|\n",
      "|  Veronica| 21|\n",
      "|Alessandro| 61|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnoheader = spark.read.load(\"./databases/persons_noheader.csv\",\\\n",
    "                            format='csv',\\\n",
    "                            header=False,\\\n",
    "                            inferSchema=True)\\\n",
    ".withColumnRenamed(\"_c0\", \"name\")\\\n",
    ".withColumnRenamed(\"_c1\", \"age\")\n",
    "\n",
    "dfnoheader.printSchema()\n",
    "dfnoheader.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-entrepreneur",
   "metadata": {},
   "source": [
    "Create an RDD from DF **persons_noheader.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecological-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRDD = dfnoheader.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-truck",
   "metadata": {},
   "source": [
    "### **Example - select two of three columns**\n",
    "Select only name and age columns and add one year to each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "patent-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|      Name| Age|Gender|\n",
      "+----------+----+------+\n",
      "| Arcangelo|  23|  Male|\n",
      "|  Leonardo|  24|  Male|\n",
      "|Margherita|  10|Female|\n",
      "|  Veronica|  21|Female|\n",
      "|Alessandro|  61|  Male|\n",
      "|   Giorgio|null|  Male|\n",
      "+----------+----+------+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfPersons = spark.read.load(\"./databases/persons_age_name_gender.csv\",\\\n",
    "                            format='csv',\\\n",
    "                            header=True,\\\n",
    "                            inferSchema=True)\n",
    "dfPersons.show()\n",
    "dfPersons.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "manufactured-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|      Name| Age|\n",
      "+----------+----+\n",
      "| Arcangelo|  23|\n",
      "|  Leonardo|  24|\n",
      "|Margherita|  10|\n",
      "|  Veronica|  21|\n",
      "|Alessandro|  61|\n",
      "|   Giorgio|null|\n",
      "+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfNameAge = dfPersons.select(\"Name\",\"Age\")\n",
    "dfNameAge.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "invisible-tennis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      Name|Newage|\n",
      "+----------+------+\n",
      "| Arcangelo|  24.0|\n",
      "|  Leonardo|  25.0|\n",
      "|Margherita|  11.0|\n",
      "|  Veronica|  22.0|\n",
      "|Alessandro|  62.0|\n",
      "|   Giorgio|  null|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnew = dfNameAge.selectExpr(\"Name\", \"Age + 1 AS Newage\")\n",
    "dfnew.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "satisfactory-intranet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Newage: double (nullable = true)\n",
      "\n",
      "+----------+------+\n",
      "|      Name|Newage|\n",
      "+----------+------+\n",
      "|Alessandro|  62.0|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = dfnew.filter(\"Age >= 30\")\n",
    "df_filtered.printSchema()\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-tamil",
   "metadata": {},
   "source": [
    "### **Example - List of tuples**\n",
    "Apply Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "clinical-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "listEmployee = [(105,'Chloe',5),\n",
    "               (103,'Paul',3),\n",
    "               (101,'John',1),\n",
    "               (102,'Lisa',2),\n",
    "               (104,'Evan',4),\n",
    "               (106,'Amy',6),]\n",
    "\n",
    "listDepartment = [(100, 'Other'),\n",
    "                 (3, 'Engineering'),\n",
    "                 (2, 'Sales'),\n",
    "                 (1, 'Marketing'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hindu-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "employeeDF = spark.createDataFrame(listEmployee, ['id','name','deptno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hazardous-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "departmentDF = spark.createDataFrame(listDepartment, ['deptno','deptName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "grave-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|deptno|\n",
      "+---+-----+------+\n",
      "|105|Chloe|     5|\n",
      "|103| Paul|     3|\n",
      "|101| John|     1|\n",
      "|102| Lisa|     2|\n",
      "|104| Evan|     4|\n",
      "|106|  Amy|     6|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeeDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "vulnerable-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|deptno|   deptName|\n",
      "+------+-----------+\n",
      "|   100|      Other|\n",
      "|     3|Engineering|\n",
      "|     2|      Sales|\n",
      "|     1|  Marketing|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departmentDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "liable-looking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      " |-- deptName: string (nullable = true)\n",
      "\n",
      "+---+----+------+------+-----------+\n",
      "| id|name|deptno|deptno|   deptName|\n",
      "+---+----+------+------+-----------+\n",
      "|101|John|     1|     1|  Marketing|\n",
      "|103|Paul|     3|     3|Engineering|\n",
      "|102|Lisa|     2|     2|      Sales|\n",
      "+---+----+------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner Join/Natural Join\n",
    "\n",
    "# The inner join is the default join in Spark SQL.\n",
    "# It selects rows that have matching values in both relations\n",
    "\n",
    "resDF = employeeDF.join(departmentDF, employeeDF.deptno==departmentDF.deptno)\n",
    "\n",
    "resDF.printSchema()\n",
    "resDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "exciting-given",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      "\n",
      "+---+----+------+\n",
      "| id|name|deptno|\n",
      "+---+----+------+\n",
      "|101|John|     1|\n",
      "|103|Paul|     3|\n",
      "|102|Lisa|     2|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left semi Join\n",
    "\n",
    "# Return values from the left side of the relation\n",
    "# that has a march with the right. It is also referred \n",
    "# to as a left join\n",
    "\n",
    "# 'leftsemi', 'left_semi'\n",
    "\n",
    "resDF = employeeDF.join(departmentDF,\\\n",
    "                        employeeDF.deptno==departmentDF.deptno,\\\n",
    "                       'leftsemi')\n",
    "\n",
    "resDF.printSchema()\n",
    "resDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "plain-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      " |-- deptName: string (nullable = true)\n",
      "\n",
      "+---+-----+------+------+-----------+\n",
      "| id| name|deptno|deptno|   deptName|\n",
      "+---+-----+------+------+-----------+\n",
      "|106|  Amy|     6|  null|       null|\n",
      "|105|Chloe|     5|  null|       null|\n",
      "|101| John|     1|     1|  Marketing|\n",
      "|103| Paul|     3|     3|Engineering|\n",
      "|102| Lisa|     2|     2|      Sales|\n",
      "|104| Evan|     4|  null|       null|\n",
      "+---+-----+------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left Outer join\n",
    "\n",
    "# Return all values from the left relation and the matched values\n",
    "# from the right relation, or appends NULL if there is no match.\n",
    "# It is also referred to as a left join\n",
    "\n",
    "# 'leftouter', 'left', 'left outer'\n",
    "\n",
    "resDF = employeeDF.join(departmentDF,\\\n",
    "                        employeeDF.deptno==departmentDF.deptno,\\\n",
    "                       'leftouter')\n",
    "\n",
    "resDF.printSchema()\n",
    "resDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "elegant-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      " |-- deptName: string (nullable = true)\n",
      "\n",
      "+----+----+------+------+-----------+\n",
      "|  id|name|deptno|deptno|   deptName|\n",
      "+----+----+------+------+-----------+\n",
      "| 101|John|     1|     1|  Marketing|\n",
      "|null|null|  null|   100|      Other|\n",
      "| 103|Paul|     3|     3|Engineering|\n",
      "| 102|Lisa|     2|     2|      Sales|\n",
      "+----+----+------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Right outer join\n",
    "\n",
    "# Return all values from the left relation and the matched values\n",
    "# from the right relation, or appends NULL if there is no match.\n",
    "# It is also referred to as a left join\n",
    "\n",
    "# 'rightouter', 'right', 'right outer'\n",
    "\n",
    "resDF = employeeDF.join(departmentDF,\\\n",
    "                        employeeDF.deptno==departmentDF.deptno,\\\n",
    "                       'right')\n",
    "\n",
    "resDF.printSchema()\n",
    "resDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "quick-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      " |-- deptName: string (nullable = true)\n",
      "\n",
      "+----+-----+------+------+-----------+\n",
      "|  id| name|deptno|deptno|   deptName|\n",
      "+----+-----+------+------+-----------+\n",
      "| 106|  Amy|     6|  null|       null|\n",
      "| 105|Chloe|     5|  null|       null|\n",
      "| 101| John|     1|     1|  Marketing|\n",
      "|null| null|  null|   100|      Other|\n",
      "| 103| Paul|     3|     3|Engineering|\n",
      "| 102| Lisa|     2|     2|      Sales|\n",
      "| 104| Evan|     4|  null|       null|\n",
      "+----+-----+------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Full outer join\n",
    "\n",
    "# Return all values from both relation, \n",
    "# appends NULL on the side where there is no match.\n",
    "# It is also referred to as a full join\n",
    "\n",
    "# 'outer', 'full', 'full outer', 'fullouter'\n",
    "\n",
    "resDF = employeeDF.join(departmentDF,\\\n",
    "                        employeeDF.deptno==departmentDF.deptno,\\\n",
    "                       'outer')\n",
    "\n",
    "resDF.printSchema()\n",
    "resDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "behavioral-liberia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- deptno: long (nullable = true)\n",
      "\n",
      "+---+-----+------+\n",
      "| id| name|deptno|\n",
      "+---+-----+------+\n",
      "|106|  Amy|     6|\n",
      "|105|Chloe|     5|\n",
      "|104| Evan|     4|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left anti join (AKA the 'not in' operation)\n",
    "\n",
    "# Return values from the left relation that has \n",
    "# no match with the right.\n",
    "# It is also referred to as a anti join\n",
    "\n",
    "# 'leftanti', 'left anti'\n",
    "\n",
    "resDF = employeeDF.join(departmentDF,\\\n",
    "                        employeeDF.deptno==departmentDF.deptno,\\\n",
    "                       'leftanti')\n",
    "\n",
    "resDF.printSchema()\n",
    "resDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-bonus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
