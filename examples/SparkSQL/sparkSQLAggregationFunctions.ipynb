{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "political-islam",
   "metadata": {},
   "source": [
    "## Aggregate Functions\n",
    "Aggregate functions are provided to compute aggregates over the set of values of columns.\n",
    "- avg(column), \n",
    "- count(column), \n",
    "- sum(column), \n",
    "- abs(column),\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "previous-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark Session object\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "#Create a DataFrame from persons.csv\n",
    "df = spark.read.load(\"./databases/persons_age.csv\", format=\"csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Compute the average of age\n",
    "averageAge = df.agg({\"age\": \"avg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unavailable-collective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|      name|age|\n",
      "+----------+---+\n",
      "| Arcangelo| 23|\n",
      "|  Leonardo| 24|\n",
      "|Margherita| 10|\n",
      "|  Veronica| 21|\n",
      "|Alessandro| 61|\n",
      "+----------+---+\n",
      "\n",
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|    27.8|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "averageAge.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outstanding-cemetery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|max(name)|avg(age)|\n",
      "+---------+--------+\n",
      "| Veronica|    27.8|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the average value over column age and the maximum over name\n",
    "dfAverageAge = df.agg({\"age\": \"avg\", \"name\": \"max\"})\n",
    "dfAverageAge.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-relay",
   "metadata": {},
   "source": [
    "**NOTE:** you can't compute twice over the same column... to do that, do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "usual-accounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- avg(age): double (nullable = true)\n",
      " |-- max(age): integer (nullable = true)\n",
      "\n",
      "+--------+--------+\n",
      "|avg(age)|max(age)|\n",
      "+--------+--------+\n",
      "|    27.8|      61|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "dfAvgMaxAge = df.agg(f.avg(\"age\"), f.max(\"age\"))\n",
    "dfAvgMaxAge.printSchema()\n",
    "dfAvgMaxAge.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "plain-cooking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- max(name): string (nullable = true)\n",
      " |-- count(1): long (nullable = false)\n",
      " |-- avg(age): double (nullable = true)\n",
      "\n",
      "+---------+--------+--------+\n",
      "|max(name)|count(1)|avg(age)|\n",
      "+---------+--------+--------+\n",
      "| Veronica|       5|    27.8|\n",
      "+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAvgMaxCount = df.agg({\"age\": \"avg\", \"name\": \"max\", \"*\":\"count\"})\n",
    "dfAvgMaxCount.printSchema()\n",
    "dfAvgMaxCount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-transcript",
   "metadata": {},
   "source": [
    "### Group By and aggregates functions\n",
    "The method groupBy(col1, .., coln) method of the DataFrame class combined with a set of aggregate methods can be used to split the input data in groups and compute aggregate function over each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aboriginal-violin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    name|age|\n",
      "+--------+---+\n",
      "|   Marco| 15|\n",
      "| Antonio| 22|\n",
      "|Giovanni| 23|\n",
      "| Antonio| 27|\n",
      "| Antonio| 12|\n",
      "|   Marco| 30|\n",
      "+--------+---+\n",
      "\n",
      "+--------+------------------+\n",
      "|    name|          avg(age)|\n",
      "+--------+------------------+\n",
      "|Giovanni|              23.0|\n",
      "| Antonio|20.333333333333332|\n",
      "|   Marco|              22.5|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from persons.csv\n",
    "df = spark.read.load( \"./databases/persons_avg_group.csv\", format=\"csv\", header=True, inferSchema=True)\n",
    "grouped = df.groupBy(\"name\").avg(\"age\")\n",
    "df.show()\n",
    "grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "small-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    name|age|\n",
      "+--------+---+\n",
      "|   Marco| 15|\n",
      "| Antonio| 22|\n",
      "|Giovanni| 23|\n",
      "| Antonio| 27|\n",
      "| Antonio| 12|\n",
      "|   Marco| 30|\n",
      "+--------+---+\n",
      "\n",
      "+--------+-----------+------------------+\n",
      "|    name|count(name)|          avg(age)|\n",
      "+--------+-----------+------------------+\n",
      "|Giovanni|          1|              23.0|\n",
      "| Antonio|          3|20.333333333333332|\n",
      "|   Marco|          2|              22.5|\n",
      "+--------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from persons.csv\n",
    "df = spark.read.load( \"./databases/persons_avg_group.csv\",format=\"csv\",header=True,inferSchema=True)\n",
    "\n",
    "grouped = df.groupBy(\"name\").agg({\"age\": \"avg\", \"name\": \"count\"})\n",
    "df.show()\n",
    "grouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-asian",
   "metadata": {},
   "source": [
    "### SORT\n",
    "The sort(col1, .., coln, ascending=True) method of the DataFrame class returns a new DataFrame that:\n",
    "- contains the same data of the input one \n",
    "- but the content is sorted by col1, .., coln \n",
    "- Ascending determines ascending vs. descending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-image",
   "metadata": {},
   "source": [
    "### DFs with SQL language\n",
    "Sparks allows querying the content of aDataFrame also by using the SQL language\n",
    "\n",
    "The createOrReplaceTempView(tableName) method of the DataFrame classcan be used to assign a “table name” to theDataFrame on which it is invoked\n",
    "\n",
    "The **sql(query)** method of the SparkSessionclass can be used to execute an SQL-like query.\n",
    "\n",
    "**NOTE:** this erases errors only at runtime when an action is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "persistent-moisture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|age|name|\n",
      "+---+----+\n",
      "| 30|John|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "\n",
    "# Create a DataFrame from persons.csv       \n",
    "df = spark.read.load( \"./databases/persons.json\", format=\"json\")\n",
    "\n",
    "# Assign the “table name” people to the df DataFrame                          \n",
    "df.createOrReplaceTempView(\"people\");\n",
    "\n",
    "# Select the persons with age between 20 and 31\n",
    "# by querying the people table               \n",
    "selectedPersons = spark.sql(\"SELECT * FROM people WHERE age>=20 and age<=31\")\n",
    "\n",
    "# Print the result on the standard output\n",
    "selectedPersons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "\n",
    "# Read persons_id.csv and store it in a DataFrame\n",
    "dfPersons = spark.read.load(\"persons_id.csv\", format=\"csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Assign the “table name” people to the dfPerson\n",
    "dfPersons.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# Read liked_sports.csv and store it in a DataFrame\n",
    "dfUidSports = spark.read.load(\"liked_sports.csv\", format=\"csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Assign the “table name” liked to dfUidSports\n",
    "dfUidSports.createOrReplaceTempView(\"liked\")\n",
    "\n",
    "# Join the two input tables by using the\n",
    "#SQL-like syntax\n",
    "dfPersonLikes = spark.sql(\"SELECT * from people,liked where people.uid=liked.uid\")\n",
    "# Print the result on the standard output\n",
    "dfPersonLikes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3\n",
    "\n",
    "# Create a DataFrame from persons.csv\n",
    "df = spark.read.load( \"persons.json\", format=\"json\")\n",
    "\n",
    "# Assign the “table name” people to the df DataFrame\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# Define groups based on the value of name and\n",
    "# compute average and number of records for each group\n",
    "nameAvgAgeCount = spark.sql(\"SELECT name, avg(age), count(name) FROM people GROUP BY name\")\n",
    "\n",
    "# Print the result on the standard output\n",
    "nameAvgAgeCount.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
