{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function print some statistics about the input RDD\n",
    "def analyzePartitions(myRDD):\n",
    "    if myRDD.partitioner is None:\n",
    "        print(\"Partioner: No partitioner\")\n",
    "    else:\n",
    "        print(\"Partioner: \"+str(myRDD.partitioner.partitionFunc))\n",
    "    \n",
    "    print(\"Num. partitions: \"+ str(myRDD.getNumPartitions()))\n",
    "    \n",
    "    # Create a local copy of the input partitions in a local Python list\n",
    "    partitions = myRDD.glom().collect()\n",
    "\n",
    "    print(\"Content of the partitions\")\n",
    "    for p in partitions:\n",
    "        print(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an initial RDD \n",
    "# Set the (minimum) number of partitions to 4\n",
    "myRDD = sc.parallelize([\"1,Post text1 ..\",\\\n",
    "                        \"2,Post text2 ..\",\\\n",
    "                        \"3,Post text3 ..\",\\\n",
    "                        \"1,Post text4 ..\",\\\n",
    "                        \"1,Post text5 ..\",\\\n",
    "                        \"2,Post text6 ..\",\\\n",
    "                        \"4,Post text7 ..\",\\\n",
    "                        \"5,Post text8 ..\",\\\n",
    "                        \"3,Post text9 ..\"], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "['1,Post text1 ..', '2,Post text2 ..']\n",
      "['3,Post text3 ..', '1,Post text4 ..']\n",
      "['1,Post text5 ..', '2,Post text6 ..']\n",
      "['4,Post text7 ..', '5,Post text8 ..', '3,Post text9 ..']\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "analyzePartitions(myRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Repartition\n",
    "#\n",
    "# Change the number of partitions to 12 (i.e., repartition the content of the input RDD and return \n",
    "# a new RDD with the same content but different partitions: 12 partitions))\n",
    "myRepartitionedRDD = myRDD.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 12\n",
      "Content of the partitions\n",
      "[]\n",
      "['1,Post text1 ..', '2,Post text2 ..']\n",
      "['4,Post text7 ..', '5,Post text8 ..', '3,Post text9 ..']\n",
      "[]\n",
      "['1,Post text5 ..', '2,Post text6 ..']\n",
      "['3,Post text3 ..', '1,Post text4 ..']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "analyzePartitions(myRepartitionedRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "['1,Post text1 ..', '2,Post text2 ..']\n",
      "['3,Post text3 ..', '1,Post text4 ..']\n",
      "['1,Post text5 ..', '2,Post text6 ..']\n",
      "['4,Post text7 ..', '5,Post text8 ..', '3,Post text9 ..']\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the initial RDD myRDD\n",
    "analyzePartitions(myRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Repartition\n",
    "#\n",
    "# Change the number of partitions to 2 (i.e., repartition the content of the input RDD and return \n",
    "# a new RDD with the same content but different partitions: 2 partitions))\n",
    "myRepartitionedRDD2 = myRDD.repartition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 2\n",
      "Content of the partitions\n",
      "['1,Post text1 ..', '2,Post text2 ..', '1,Post text5 ..', '2,Post text6 ..', '4,Post text7 ..', '5,Post text8 ..', '3,Post text9 ..']\n",
      "['3,Post text3 ..', '1,Post text4 ..']\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "analyzePartitions(myRepartitionedRDD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "['1,Post text1 ..', '2,Post text2 ..']\n",
      "['3,Post text3 ..', '1,Post text4 ..']\n",
      "['1,Post text5 ..', '2,Post text6 ..']\n",
      "['4,Post text7 ..', '5,Post text8 ..', '3,Post text9 ..']\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the initial RDD\n",
    "analyzePartitions(myRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# coalesce\n",
    "#\n",
    "# Coalesce is better than repartition when you are decreasing the number of partitions (it minimizes shuffles)\n",
    "# Change the number of partitions to 2 (i.e., repartition the content of the input RDD and return \n",
    "# a new RDD with the same content but different partitions: 2 partitions))\n",
    "myRepartitionedRDD3 = myRDD.coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 2\n",
      "Content of the partitions\n",
      "['1,Post text1 ..', '2,Post text2 ..', '3,Post text3 ..', '1,Post text4 ..']\n",
      "['1,Post text5 ..', '2,Post text6 ..', '4,Post text7 ..', '5,Post text8 ..', '3,Post text9 ..']\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "analyzePartitions(myRepartitionedRDD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "['1,Post text1 ..', '2,Post text2 ..']\n",
      "['3,Post text3 ..', '1,Post text4 ..']\n",
      "['1,Post text5 ..', '2,Post text6 ..']\n",
      "['4,Post text7 ..', '5,Post text8 ..', '3,Post text9 ..']\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the initial RDD myRDD\n",
    "analyzePartitions(myRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a map transformation to return an RDD of pairs\n",
    "# - key: postID\n",
    "# - value: content of the post\n",
    "\n",
    "myPairRDD = myRDD.map(lambda post: (int(post.split(',')[0]), post.split(',')[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(1, 'Post text1 ..'), (2, 'Post text2 ..')]\n",
      "[(3, 'Post text3 ..'), (1, 'Post text4 ..')]\n",
      "[(1, 'Post text5 ..'), (2, 'Post text6 ..')]\n",
      "[(4, 'Post text7 ..'), (5, 'Post text8 ..'), (3, 'Post text9 ..')]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Note that the number of partitions is the same and also the \"content\" of the partitions is similar\n",
    "analyzePartitions(myPairRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a new rdd of pairs with only 2 partitions by using coaleasce\n",
    "myPairRDD2 = myPairRDD.coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 2\n",
      "Content of the partitions\n",
      "[(1, 'Post text1 ..'), (2, 'Post text2 ..'), (3, 'Post text3 ..'), (1, 'Post text4 ..')]\n",
      "[(1, 'Post text5 ..'), (2, 'Post text6 ..'), (4, 'Post text7 ..'), (5, 'Post text8 ..'), (3, 'Post text9 ..')]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "analyzePartitions(myPairRDD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# partitionBy()\n",
    "#\n",
    "# Return a new rdd of pairs with only 2 partitions. \n",
    "# Use partitionBy and the hash partition function to put all the pairs associated with the same key \n",
    "# in the same partition.\n",
    "# Each partition can contain pairs associated with different keys\n",
    "myPairRDD3 = myPairRDD.partitionBy(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <function portable_hash at 0x7f54ac3447b8>\n",
      "Num. partitions: 2\n",
      "Content of the partitions\n",
      "[(2, 'Post text2 ..'), (2, 'Post text6 ..'), (4, 'Post text7 ..')]\n",
      "[(1, 'Post text1 ..'), (3, 'Post text3 ..'), (1, 'Post text4 ..'), (1, 'Post text5 ..'), (5, 'Post text8 ..'), (3, 'Post text9 ..')]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Note that all the pairs associated with the same key are stored in the same partition\n",
    "# Given an input pair, spark associates that pair to partition number hash(key)%num.partitions\n",
    "analyzePartitions(myPairRDD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# partitionBy()\n",
    "#\n",
    "# A custom partition function to put all the pairs associated with keys <3 in\n",
    "# one partition and those associated with keys >=3 in another.\n",
    "def myPartitionFunction(key):\n",
    "    if key<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a new rdd of pairs with only 2 partitions. \n",
    "# Use partitionBy and the custom partition function to put all the pairs associated with keys <3 in\n",
    "# one partition and those associated with keys >=3 in the other.\n",
    "myPairRDD4 = myPairRDD.partitionBy(2, myPartitionFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <function myPartitionFunction at 0x7f54951510d0>\n",
      "Num. partitions: 2\n",
      "Content of the partitions\n",
      "[(1, 'Post text1 ..'), (2, 'Post text2 ..'), (1, 'Post text4 ..'), (1, 'Post text5 ..'), (2, 'Post text6 ..')]\n",
      "[(3, 'Post text3 ..'), (4, 'Post text7 ..'), (5, 'Post text8 ..'), (3, 'Post text9 ..')]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Note that all the pairs associated with odd keys are stored in one partition and\n",
    "# the pairs associated with even keys are stored in the other partition\n",
    "# Given an input pair, spark associates that pair to partition number myPartitionFunction(key)%num.partitions\n",
    "analyzePartitions(myPairRDD4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if I set the number of partitions to 4 and I use myPartitionFunction to partition pairs?\n",
    "myPairRDD5 = myPairRDD.partitionBy(4, myPartitionFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <function myPartitionFunction at 0x7f54951510d0>\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(1, 'Post text1 ..'), (2, 'Post text2 ..'), (1, 'Post text4 ..'), (1, 'Post text5 ..'), (2, 'Post text6 ..')]\n",
      "[(3, 'Post text3 ..'), (4, 'Post text7 ..'), (5, 'Post text8 ..'), (3, 'Post text9 ..')]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Note that one two partitions contain some pairs\n",
    "# because myPartitionFunction(key)%num.partitions can assume only on the following two values: 0, 1\n",
    "analyzePartitions(myPairRDD5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples to analyze the impacts of transformations on the partitions and partitioner of the the returned RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(1, 'Post text1 ..'), (2, 'Post text2 ..')]\n",
      "[(3, 'Post text3 ..'), (1, 'Post text4 ..')]\n",
      "[(1, 'Post text5 ..'), (2, 'Post text6 ..')]\n",
      "[(4, 'Post text7 ..'), (5, 'Post text8 ..'), (3, 'Post text9 ..')]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the input RDD of pairs myPairRDD\n",
    "analyzePartitions(myPairRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the content of myPairRDD\n",
    "filteredPairRDD = myPairRDD.filter(lambda pair: pair[0]!=5 and pair[0]!=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(1, 'Post text1 ..'), (2, 'Post text2 ..')]\n",
      "[(1, 'Post text4 ..')]\n",
      "[(1, 'Post text5 ..'), (2, 'Post text6 ..')]\n",
      "[(4, 'Post text7 ..')]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Same number of partitions and same partitioner (no partitioner in this case)\n",
    "analyzePartitions(filteredPairRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize pairs by using the hash partition function. Keep the same number of partitions of the input pair RDD\n",
    "myPairRDD6 = myPairRDD.partitionBy(myPairRDD.getNumPartitions(), hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <built-in function hash>\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(4, 'Post text7 ..')]\n",
      "[(1, 'Post text1 ..'), (1, 'Post text4 ..'), (1, 'Post text5 ..'), (5, 'Post text8 ..')]\n",
      "[(2, 'Post text2 ..'), (2, 'Post text6 ..')]\n",
      "[(3, 'Post text3 ..'), (3, 'Post text9 ..')]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "analyzePartitions(myPairRDD6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the content of myPairRDD6\n",
    "filteredPairRDD6 = myPairRDD6.filter(lambda pair: pair[0]!=5 and pair[0]!=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <built-in function hash>\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(4, 'Post text7 ..')]\n",
      "[(1, 'Post text1 ..'), (1, 'Post text4 ..'), (1, 'Post text5 ..')]\n",
      "[(2, 'Post text2 ..'), (2, 'Post text6 ..')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Same number of partitions and same partitioner (hash function)\n",
    "analyzePartitions(filteredPairRDD6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a map transformation to change the value part of the input pairs of myPairRDD6\n",
    "# - key = input key\n",
    "# - value = len(input value)\n",
    "mapPairRDD6 = myPairRDD6.map(lambda pair: (pair[0], len(pair[1])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(4, 13)]\n",
      "[(1, 13), (1, 13), (1, 13), (5, 13)]\n",
      "[(2, 13), (2, 13)]\n",
      "[(3, 13), (3, 13)]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Same number of partitions but note that there is no partitioner.\n",
    "# No shuffle because data are not sent on the network to apply map but but no partitioner.\n",
    "# Pay attention that map causes the new returned RDD of pairs to forget the parent's partitioning information.\n",
    "# The lambda function we used in the map transformation is not changing the key part but the system does not \n",
    "# know it\n",
    "analyzePartitions(mapPairRDD6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can specify that you are not changing the key part by using the preservesPartitioning parameter\n",
    "mapPairRDD7 = myPairRDD6.map(lambda pair: (pair[0], len(pair[1])), preservesPartitioning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <built-in function hash>\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(4, 13)]\n",
      "[(1, 13), (1, 13), (1, 13), (5, 13)]\n",
      "[(2, 13), (2, 13)]\n",
      "[(3, 13), (3, 13)]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Same number of partitions and also same partitioner in this case.\n",
    "# Pay attention that the system trusts you. If you set preservesPartitioning to True but your map\n",
    "# function changes the key part of the pairs the next operations could be wrong.\n",
    "analyzePartitions(mapPairRDD7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <built-in function hash>\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(4, 'Post text7 ..')]\n",
      "[(1, 'Post text1 ..'), (1, 'Post text4 ..'), (1, 'Post text5 ..'), (5, 'Post text8 ..')]\n",
      "[(2, 'Post text2 ..'), (2, 'Post text6 ..')]\n",
      "[(3, 'Post text3 ..'), (3, 'Post text9 ..')]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the input RDD of pairs myPairRDD6\n",
    "analyzePartitions(myPairRDD6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a mapValues transformation to change the value part of the input pairs of myPairRDD6\n",
    "# - key = input key\n",
    "# - value = len(input value)\n",
    "mapPairRDD8 = myPairRDD6.mapValues(lambda value: len(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <built-in function hash>\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(4, 13)]\n",
      "[(1, 13), (1, 13), (1, 13), (5, 13)]\n",
      "[(2, 13), (2, 13)]\n",
      "[(3, 13), (3, 13)]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Same number of partitions and also same partitioner in this case because mapValues does not change the\n",
    "# value part of the input pairs.\n",
    "analyzePartitions(mapPairRDD8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: No partitioner\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(4, 13)]\n",
      "[(1, 13), (1, 13), (1, 13), (5, 13)]\n",
      "[(2, 13), (2, 13)]\n",
      "[(3, 13), (3, 13)]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the input RDD of pairs mapPairRDD6\n",
    "analyzePartitions(mapPairRDD6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply reduceByKey to sum the values for each each key\n",
    "keySumRDD = mapPairRDD6.reduceByKey(lambda v1,v2: v1+v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioner: <function portable_hash at 0x7f54ac3447b8>\n",
      "Num. partitions: 4\n",
      "Content of the partitions\n",
      "[(4, 13)]\n",
      "[(1, 39), (5, 13)]\n",
      "[(2, 26)]\n",
      "[(3, 26)]\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics\n",
    "# Note that the returned RDD is partitioned. \n",
    "# The system applies the hash partition function during the shuffle step that is executed before the \n",
    "# computation of the final result for each key\n",
    "analyzePartitions(keySumRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
