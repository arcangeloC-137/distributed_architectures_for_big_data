{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "visible-wesley",
   "metadata": {},
   "source": [
    "# **Parameter Tuning**\n",
    "The setting of the parameters of an algorithm is always a difficult task\n",
    "- A “brute force” approach can be used to find the setting optimizing a quality index\n",
    "- The training data is split in two subsets\n",
    "    - The first set is used to build a model\n",
    "    - The second one is used to evaluate the quality of the model\n",
    "- The setting that maximizes a quality index (e.g., the prediction accuracy) is used to build the final model on the whole training dataset.\n",
    "\n",
    "Hence, the cross-validation approach is usually used. It creates k splits and k models. For each configuration the system will apply k models, and the total number of model is equal to k-times the number in the configuration.\n",
    "\n",
    "Input:\n",
    "   - An MLlib pipeline\n",
    "   - A set of values to be evaluated for each input parameter of the pipeline\n",
    "       - All the possible combinations of the specified parameter values are considered and the related models are automatically generated and evaluated by Spark.\n",
    "   - A quality evaluation metric to evaluate the result of the input pipeline\n",
    "\n",
    "Output:\n",
    "   - The model associated with the best parameter setting, in term of quality evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recognized-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output folders\n",
    "# input and output folders\n",
    "trainingData = \"./databases/trainingData.csv\"\n",
    "unlabeledData = \"./databases/unlabeledData.csv\"\n",
    "outputPath = \"./tuning/\"\n",
    "\n",
    "# Training data in raw format\n",
    "labeledDataDF = spark.read.load(trainingData,\\\n",
    "                                format=\"csv\",\\\n",
    "                                header=True,\\\n",
    "                                inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "drawn-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Training step\n",
    "# *************************\n",
    "\n",
    "# Define an assembler to create a column (features) of type Vector\n",
    "# containing the double values associated with columns attr1, attr2, attr3\n",
    "assembler = VectorAssembler(inputCols=[\"attr1\", \"attr2\", \"attr3\"],\\\n",
    "                                    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lonely-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "pipeline = Pipeline().setStages([assembler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-hotel",
   "metadata": {},
   "source": [
    "**Parameter Grid** construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "variable-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    ".addGrid(lr.maxIter, [10, 100, 1000])\\\n",
    ".addGrid(lr.regParam, [0.1, 0.01])\\\n",
    ".build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secondary-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now treat the Pipeline as an Estimator, wrapping it in a\n",
    "# CrossValidator instance. This allows us to jointly choose parameters\n",
    "# for all Pipeline stages.\n",
    "# CrossValidator requires\n",
    "# - an Estimator\n",
    "# - a set of Estimator ParamMaps\n",
    "# - an Evaluator.\n",
    "\n",
    "cv = CrossValidator()\\\n",
    ".setEstimator(pipeline)\\\n",
    ".setEstimatorParamMaps(paramGrid)\\\n",
    ".setEvaluator(BinaryClassificationEvaluator())\\\n",
    ".setNumFolds(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "preceding-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation. The result is the logistic regression model\n",
    "# based on the best set of parameters (based on the results of the\n",
    "# cross-validation operation).\n",
    "tunedLRmodel = cv.fit(labeledDataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "official-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Prediction step\n",
    "# *************************\n",
    "\n",
    "unlabeledData = spark.read.load(unlabeledData,\\\n",
    "format=\"csv\", header=True, inferSchema=True)\n",
    "predictionsDF = tunedLRmodel.transform(unlabeledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wicked-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictionsDF.select(\"attr1\", \"attr2\", \"attr3\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "promising-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-----+\n",
      "|label|attr1|attr2|attr3|\n",
      "+-----+-----+-----+-----+\n",
      "|  1.0|  0.0|  1.1|  0.1|\n",
      "|  0.0|  2.0|  1.0| -1.0|\n",
      "|  0.0|  2.0|  1.3|  1.0|\n",
      "|  1.0|  0.0|  1.2| -0.5|\n",
      "+-----+-----+-----+-----+\n",
      "\n",
      "+-----+-----+-----+-----+--------------+--------------------+--------------------+----------+\n",
      "|label|attr1|attr2|attr3|      features|       rawPrediction|         probability|prediction|\n",
      "+-----+-----+-----+-----+--------------+--------------------+--------------------+----------+\n",
      "| null| -1.0|  1.5|  1.3|[-1.0,1.5,1.3]|[-2.9809716290125...|[0.04829295232390...|       1.0|\n",
      "| null|  3.0|  2.0| -0.1|[3.0,2.0,-0.1]|[1.84892116210460...|[0.86400038529945...|       0.0|\n",
      "| null|  0.0|  2.2| -1.5|[0.0,2.2,-1.5]|[-2.9350858066952...|[0.05044615025400...|       1.0|\n",
      "+-----+-----+-----+-----+--------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labeledDataDF.show()\n",
    "predictionsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-output",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
