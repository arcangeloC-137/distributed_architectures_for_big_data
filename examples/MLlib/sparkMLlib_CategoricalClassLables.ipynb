{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "major-tourism",
   "metadata": {},
   "source": [
    "# Categorical Class Lables\n",
    "Usually the class label is a categorical value (i.e., a string). As reported before, Spark MLlib works only with numerical values and hence categorical class label values must be mapped to integer (and then double) values.\n",
    "\n",
    "The Estimator StringIndexer and theTransformer IndexToString support thetransformation of categorical class label intonumerical one and vice versa.\n",
    "\n",
    "Main steps:\n",
    "1. Use StringIndexer to extend the input DataFrame with a new column, called “label”, containing the numerical representation of the class label column\n",
    "2. Create a column, called “features”, of type vector containing the predictive features\n",
    "3. Infer a classification model by using a classification algorithm (e.g., Decision Tree, Logistic regression). The model is built by considering only the values of features and label. All the other columns are not considered by the classification algorithm during the generation of the prediction mode.\n",
    "4. Apply the model on a set of unlabeled data to predict their numerical class label\n",
    "5. Use IndexToString to convert the predicted numerical class label values to the original categorical values\n",
    "\n",
    "### We make the same operation as for the Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "# input and output folders\n",
    "trainingData = \"ex_dataCategorical/trainingData.csv\"\n",
    "unlabeledData = \"ex_dataCategorical/unlabeledData.csv\"\n",
    "outputPath = \"predictionsDTCategoricalPipeline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Training step\n",
    "# *************************\n",
    "\n",
    "# Create a DataFrame from trainingData.csv\n",
    "# Training data in raw format\n",
    "trainingData = spark.read.load(trainingData, format=\"csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Define an assembler to create a column (features) of type Vector\n",
    "# containing the double values associated with columns attr1, attr2, attr3\n",
    "assembler = VectorAssembler(inputCols=[\"attr1\", \"attr2\", \"attr3\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-bracelet",
   "metadata": {},
   "source": [
    "### Here the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The StringIndexer Estimator is used to map each class label\n",
    "# value to an integer value (casted to a double).\n",
    "# A new attribute called label is generated by applying\n",
    "# transforming the content of the categoricalLabel attribute.\n",
    "labelIndexer = StringIndexer(inputCol=\"categoricalLabel\", outputCol=\"label\",\\\n",
    "                                handleInvalid=\"keep\").fit(trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DecisionTreeClassifier object.\n",
    "# DecisionTreeClassifier is an Estimator that is used to\n",
    "# create a classification model based on decision trees.\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# We can set the values of the parameters of the DecisionTree\n",
    "# For example we can set the measure that is used to decide if a\n",
    "# node must be split.\n",
    "# In this case we set gini index\n",
    "dt.setImpurity(\"gini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-motivation",
   "metadata": {},
   "source": [
    "### Finally, we convert the result from numerical to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end of the pipeline we must convert indexed labels back\n",
    "# to original labels (from numerical to string).\n",
    "# The content of the prediction attribute is the index of the predicted class\n",
    "# The original name of the predicted class is stored in the predictedLabel\n",
    "# attribute.\n",
    "\n",
    "# IndexToString creates a new column (called predictedLabel in\n",
    "# this example) that is based on the content of the prediction column.\n",
    "# prediction is a double while predictedLabel is a string\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\\\n",
    "                                    labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline that is used to create the decision tree\n",
    "# model on the training data. The pipeline includes also\n",
    "# the preprocessing and postprocessing steps\n",
    "pipeline = Pipeline().setStages([assembler, labelIndexer, dt, labelConverter])\n",
    "\n",
    "# Execute the pipeline on the training data to build the\n",
    "# classification model\n",
    "classificationModel = pipeline.fit(trainingData)\n",
    "# Now, the classification model can be used to predict the class label\n",
    "# of new unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Prediction step\n",
    "# *************************\n",
    "# Create a DataFrame from unlabeledData.csv\n",
    "# Unlabeled data in raw format\n",
    "unlabeledData = spark.read.load(unlabeledData, format=\"csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Make predictions on the unlabled data using the transform() method of the\n",
    "# trained classification model transform uses only the content of 'features'\n",
    "# to perform the predictions.The model is associated with the pipeline and hence\n",
    "# also the assembler is executed\n",
    "predictions = classificationModel.transform(unlabeledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The returned DataFrame has the following schema (attributes)\n",
    "# - attr1: double (nullable = true)\n",
    "# - attr2: double (nullable = true)\n",
    "# - attr3: double (nullable = true)\n",
    "# - features: vector (values of the attributes)\n",
    "# - label: double (value of the class label)\n",
    "# - rawPrediction: vector (nullable = true)\n",
    "# - probability: vector (The i-th cell contains the probability that the\n",
    "# current record belongs to the i-th class\n",
    "# - prediction: double (the predicted class label)\n",
    "# - predictedLabel: string (nullable = true)\n",
    "\n",
    "# Select only the original features (i.e., the value of the original attributes\n",
    "# attr1, attr2, attr3) and the predicted class for each record\n",
    "predictions = predictionsDF.select(\"attr1\", \"attr2\", \"attr3\", \"predictedLabel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
