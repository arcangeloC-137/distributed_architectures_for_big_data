{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "failing-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 38 - Find sensors with at least two readings and with pm10 above threshold of 50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "social-laser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.42.11.7:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0-cdh6.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reverse-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"/data/students/bigdata-01QYD/ex_data/Ex38/data/\"\n",
    "logRDD = sc.textFile(inputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-purpose",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ideal-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50.0\n",
    "\n",
    "criticalSensors = logRDD.map(lambda logline: (logline.split(',')[0],float(logline.split(',')[2])))\\\n",
    "                        .filter(lambda keyVal: keyVal[1]>=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rental-bachelor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 60.2), ('s1', 55.5), ('s2', 52.5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criticalSensors.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "affected-indicator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = criticalSensors.combineByKey(lambda inputElem: (inputElem,1),\n",
    "                                     lambda inElem, inputElem: (inElem[0]+inputElem, inElem[1]+1),\n",
    "                                     lambda inElem1, inElem2: (inElem1[0]+inElem2[0],inElem1[1]+inElem2[1]))\\\n",
    "                        .filter(lambda criticalSensor: criticalSensor[1][1]>=2)\\\n",
    "                        .map(lambda criticalSensor: (criticalSensor[0],criticalSensor[1][1]))\n",
    "\n",
    "# we apply filter as second step since the output of combineByKey is like ('s1', (115.7, 2)\n",
    "\n",
    "result.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-tourist",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "suitable-language",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 2)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm10Critical = logRDD.filter(lambda logline: float(logline.split(',')[2])>=threshold)\n",
    "crtSensors = pm10Critical.map(lambda logline: (logline.split(',')[0], 1))\n",
    "\n",
    "resultWithReduce = crtSensors.reduceByKey(lambda v1,v2: v1+v2).filter(lambda criticalSensor: criticalSensor[1]>=2)\n",
    "resultWithReduce.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-inventory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
