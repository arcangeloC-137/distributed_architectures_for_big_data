{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecological-greek",
   "metadata": {},
   "source": [
    "## **Exercise 51 - Classification problem**\n",
    "\n",
    "Input:\n",
    "- A training data set containing a set of sentences\n",
    "    - One sentence per line\n",
    "    - Schema\n",
    "        - label: 1 (Spark related sentence) or 0 (Non-spark related sentence)\n",
    "        - text: a sentence about something\n",
    "- A set of unlabeled sentences\n",
    "\n",
    "Output:\n",
    "- For each unlabeled sentence the predicted class label value by using a logistic regression algorithm\n",
    "\n",
    "You must train the model by using as input two predictive features:\n",
    " - The number of words in each sentence\n",
    " - A Boolean value associated with the presence/absence of the word “Spark” in the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "italic-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# input and output folders\n",
    "trainingData = \"/data/students/bigdata-01QYD/ex_data/Ex51/data//trainingData.csv\"\n",
    "unlabeledData = \"/data/students/bigdata-01QYD/ex_data/Ex51/data//unlabeledData.csv\"\n",
    "outputPath = \"./res_ex51/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "commercial-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Training step\n",
    "# *************************\n",
    "\n",
    "# Create a DataFrame from trainingData.csv\n",
    "# Training data in raw format\n",
    "trainingData = spark.read.load(trainingData,\\\n",
    "                                format=\"csv\",\\\n",
    "                                header=True,\\\n",
    "                                inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "informed-carnival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    1|The Spark system ...|\n",
      "|    1|Spark is a new di...|\n",
      "|    0|Turin is a beauti...|\n",
      "|    0|Turin is in the n...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.printSchema()\n",
    "trainingData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equipped-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Python function that returns the number \n",
    "# of words occuring in the input string\n",
    "def countWords(text):\n",
    "    return len(text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reliable-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.countWords(text)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We register a UDF function and explicitly report data type\n",
    "spark.udf.register('countWords', countWords, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stunning-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funct that checks if the input string contains the word 'Spark'\n",
    "def containsSpark(text):\n",
    "    return text.find('Spark')>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "enhanced-bonus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.containsSpark(text)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We register a UDF function and explicitly report data type\n",
    "spark.udf.register('containsSpark', containsSpark, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intermediate-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SQLTransformer to add two column to the input DF\n",
    "# numLines and SparkWord\n",
    "sqlTrans = SQLTransformer(statement= \"\"\"SELECT *,\n",
    "                                        countWords(text) AS numLines,\n",
    "                                        containsSpark(text) AS SparkWord\n",
    "                                        FROM __THIS__\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powered-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an assembler to combine \"numLines\" and \"SparkWord\" in a Vector\n",
    "assembler = VectorAssembler(inputCols=['numLines','SparkWord'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "level-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification model based on the logistic regression\n",
    "lr = LogisticRegression()\\\n",
    ".setMaxIter(10)\\\n",
    ".setRegParam(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "atomic-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline \n",
    "pipeline = Pipeline().setStages([sqlTrans, assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "literary-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hydraulic-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Prediction step\n",
    "# *************************\n",
    "\n",
    "# Create a DataFrame from unlabeledData.csv\n",
    "# Unlabeled data in raw format\n",
    "unlabeledData = spark.read.load(unlabeledData,\\\n",
    "format=\"csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "oriented-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "| null|Spark performs be...|\n",
      "| null|Comparison betwee...|\n",
      "| null|Turin is in Piedmont|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unlabeledData.printSchema()\n",
    "unlabeledData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "entitled-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the unlabled data using the transform() method of the\n",
    "# trained classification model transform uses only the content of 'features'\n",
    "# to perform the predictions\n",
    "predictionsDF = classificationModel.transform(unlabeledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ruled-yahoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- numLines: integer (nullable = true)\n",
      " |-- SparkWord: boolean (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "+-----+-----------------------------------+--------+---------+---------+----------------------------------------+----------------------------------------+----------+\n",
      "|label|text                               |numLines|SparkWord|features |rawPrediction                           |probability                             |prediction|\n",
      "+-----+-----------------------------------+--------+---------+---------+----------------------------------------+----------------------------------------+----------+\n",
      "|null |Spark performs better than Hadoop  |5       |true     |[5.0,1.0]|[-3.1272480248757137,3.1272480248757137]|[0.04199718899423514,0.9580028110057648]|1.0       |\n",
      "|null |Comparison between Spark and Hadoop|5       |true     |[5.0,1.0]|[-3.1272480248757137,3.1272480248757137]|[0.04199718899423514,0.9580028110057648]|1.0       |\n",
      "|null |Turin is in Piedmont               |4       |false    |[4.0,0.0]|[3.1996699996002347,-3.1996699996002347]|[0.9608218568157129,0.03917814318428712]|0.0       |\n",
      "+-----+-----------------------------------+--------+---------+---------+----------------------------------------+----------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDF.printSchema()\n",
    "predictionsDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "judicial-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "+-----------------------------------+----------+\n",
      "|text                               |prediction|\n",
      "+-----------------------------------+----------+\n",
      "|Spark performs better than Hadoop  |1.0       |\n",
      "|Comparison between Spark and Hadoop|1.0       |\n",
      "|Turin is in Piedmont               |0.0       |\n",
      "+-----------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predictionsDF.select('text', 'prediction')\n",
    "predictions.printSchema()\n",
    "predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssave the result in an HDFS output folder\n",
    "predictions.write.csv(ouputPath, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
